{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE with disentanglement"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "auto encodeur variationnel avec demelage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "==========================================================¶\n",
    "Date : 02 dec. 2018\n",
    "MS Valdom > apprenants > omar attaf, laurent lapasset, didier le picaut\n",
    "Version = 2.0\n",
    "=========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syllabus - auto encoder (AE)\n",
    "# http://www.xavierdupre.fr/app/ensae_teaching_dl/helpsphinx//chapters/deep_apprentissage_sans_labels.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que sont les auto-encodeurs\n",
    "# https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Awesome-Pytorch-list\n",
    "#https://github.com/bharathgs/Awesome-pytorch-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://ml-cheatsheet.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# == EXECUTIVE SUMMARY:\n",
    ". [Epoch = 200, average loss= 0.001] vs [Epoch = 1, average loss = 0.0016]\n",
    ". perte d'information ~ 0.1%\n",
    ". temps instance  ~ 6 mn\n",
    ". pas necessaire de faire 200 Epochs (?)\n",
    ". average loss = 0.001 pour Epoch = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================\n",
    "# autocompletion\n",
    "# =================\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer les libraries\n",
    "from __future__ import print_function\n",
    "#import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debut du decompte du temps\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#== sanity check : library cuda est-elle presente ?\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#== sanity check : presence du framework cudnn ?\n",
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f37f4152fb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reproductibilite\n",
    "SEED = 1\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametrer a la main (ne pas passer par argparse)\n",
    "batchsize=BATCH_SIZE= 128\n",
    "EPOCHS = 15\n",
    "loginterval =LOG_INTERVAL = 10\n",
    "CUDA = True\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaration de la var d'espace latent\n",
    "ZDIMS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instances de DataLoader chargent les tenseurs in cuda-memory \n",
    "kwargs = {'num_workers': 11, 'pin_memory': True} if cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formation des dataset train et test a partir de Mnist\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batchsize, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batchsize, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaration du modele VAE\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "# encodeur\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc21 = nn.Linear(400, ZDIMS)\n",
    "        self.fc22 = nn.Linear(400, ZDIMS)\n",
    "\n",
    "# decodeur        \n",
    "        self.fc3 = nn.Linear(ZDIMS, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "# sorties(mu, logvar): \n",
    "# moy et var, une pour chaque dimension latente, \n",
    "\n",
    "    def encode(self, x: Variable) -> (Variable, Variable):\n",
    "        h1 = self.relu(self.fc1(x))  \n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "# sur train\n",
    "# - prenez mu, var appris pour chacune des dimensions de ZDIMS et tirez échantillon\n",
    "# aléatoire de cette distribution    \n",
    "# - l'ensemble du réseau est formé de sorte que ces échantillons dessinés au \n",
    "# hasard se décodent en sortie qui ressemble à l'entrée    \n",
    "# - ce qui signifie que mu, var sera appris des distributions qui codent \n",
    "# les entrées    \n",
    "# - en raison du terme KLD supplémentaire (voir loss_function () \n",
    "# ci-dessous), la distribution aura tendance à unifier les Gaussiens     \n",
    "\n",
    "    \n",
    "    def reparameterize(self, mu: Variable, logvar: Variable) -> Variable:\n",
    "        if self.training: \n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z: Variable) -> Variable:\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        return self.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x: Variable) -> (Variable, Variable, Variable):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "model = VAE()\n",
    "if cuda:\n",
    "    model.cuda()   \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KLD est la deviation Kullback-Leibler\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar) -> Variable:\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784))\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "# Normaliser par le même nombre d'éléments que dans la reconstruction \n",
    "    KLD /= BATCH_SIZE * 784\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "def train(epoch):\n",
    "   \n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        recon_batch, mu, logvar = model(data)\n",
    "       \n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        \n",
    "        losses.append(loss.cpu().item())\n",
    "        \n",
    "        loss.backward()\n",
    "        #train_loss += loss.data[0]\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                #loss.data[0] \n",
    "                loss.item()/ len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "  \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            if CUDA:\n",
    "            # make sure this lives on the GPU\n",
    "                data = data.cuda()\n",
    "\n",
    "            data = Variable(data, volatile=True)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "        #test_loss += loss_function(recon_batch, data, mu, logvar).data[0]\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "        \n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(BATCH_SIZE, 1, 28, 28)[:n]])\n",
    "          \n",
    "                save_image(comparison.data.cpu(),\n",
    "                         'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.005489\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.003201\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.002365\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.002178\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.002024\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.002085\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.002037\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.001958\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.001932\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.001850\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.001833\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.001804\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.001734\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.001621\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.001672\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.001603\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.001636\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.001566\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.001584\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.001525\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.001468\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.001503\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.001548\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.001445\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.001466\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.001464\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.001417\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.001377\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.001475\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.001374\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.001422\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.001409\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.001358\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.001347\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.001343\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.001336\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.001357\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.001290\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.001357\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.001306\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.001307\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.001361\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.001363\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.001301\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.001251\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.001321\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.001304\n",
      "====> Epoch: 1 Average loss: 0.0016\n",
      "====> Test set loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlp/anaconda3/envs/pytorch36/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.001238\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.001284\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.001215\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.001280\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.001232\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.001307\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.001269\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.001235\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.001232\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.001232\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.001176\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.001234\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.001297\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.001249\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.001226\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.001232\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.001237\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.001201\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.001242\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.001205\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.001183\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.001196\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.001263\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.001191\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.001243\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.001233\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.001196\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.001200\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.001209\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.001196\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.001215\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.001236\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.001160\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.001192\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.001208\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.001189\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.001190\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.001160\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.001174\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.001174\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.001216\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.001173\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.001171\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.001163\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.001147\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.001213\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.001214\n",
      "====> Epoch: 2 Average loss: 0.0012\n",
      "====> Test set loss: 0.0011\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.001139\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.001201\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.001167\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.001229\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.001165\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.001155\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.001230\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.001139\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.001168\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.001184\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.001120\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.001169\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.001128\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.001114\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.001123\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.001128\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.001155\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.001130\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.001154\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.001088\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.001114\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.001118\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.001111\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.001166\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.001146\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.001171\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.001115\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.001173\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.001132\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.001181\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.001139\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.001151\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.001115\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.001084\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.001170\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.001097\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.001134\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.001070\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.001158\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.001148\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.001145\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.001128\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.001113\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.001165\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.001134\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.001106\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.001134\n",
      "====> Epoch: 3 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.001133\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.001099\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.001117\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.001098\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.001110\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.001091\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.001137\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.001140\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.001125\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.001175\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.001106\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.001129\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.001102\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.001119\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.001146\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.001100\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.001162\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.001101\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.001071\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.001125\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.001137\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.001113\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.001118\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.001102\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.001128\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.001108\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.001112\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.001087\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.001113\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.001121\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.001085\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.001116\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.001162\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.001102\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.001092\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.001113\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.001102\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.001104\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.001132\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.001097\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.001142\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.001119\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.001104\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.001097\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.001102\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.001090\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.001092\n",
      "====> Epoch: 4 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001078\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.001059\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.001087\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.001098\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.001120\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.001111\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.001082\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.001101\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.001086\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.001093\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.001155\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.001104\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.001085\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.001127\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.001144\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.001153\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.001049\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.001096\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.001088\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.001086\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.001094\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.001092\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.001045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.001063\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.001124\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.001121\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.001119\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.001120\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.001108\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.001069\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.001098\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.001043\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.001043\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.001096\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.001133\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.001051\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.001083\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.001149\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.001106\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.001118\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.001088\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.001075\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.001087\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.001095\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.001088\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.001126\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.001092\n",
      "====> Epoch: 5 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.001075\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.001077\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.001116\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.001064\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.001081\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.001104\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.001117\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.001134\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.001082\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.001082\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.001058\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.001066\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.001040\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.001058\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.001082\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.001085\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.001099\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.001076\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.001089\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.001045\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.001084\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.001121\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.001094\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.001102\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.001028\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.001114\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.001091\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.001072\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.001048\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.001049\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.001106\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.001095\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.001067\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.001102\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.001045\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.001113\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.001098\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.001078\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.001104\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.001099\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.001089\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.001067\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.001088\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.001044\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.001106\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.001088\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.001099\n",
      "====> Epoch: 6 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.001069\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.001100\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.001103\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.001065\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.001046\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.001049\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.001114\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.001070\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.001063\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.001091\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.001089\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.001084\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.001046\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.001111\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.001071\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.001083\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.001088\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.001071\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.001096\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.001064\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.001099\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.001065\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.001082\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.001100\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.001078\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.001094\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.001035\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.001064\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.001031\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.001072\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.001042\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.001053\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.001107\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.001090\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.001062\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.001056\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.001085\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.001091\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.001074\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.001113\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.001102\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.001071\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.001094\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.001035\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.001045\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.001082\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.001098\n",
      "====> Epoch: 7 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.001093\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.001139\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.001074\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.001090\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.001048\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.001054\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.001056\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.001076\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.001094\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.001071\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.001097\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.001107\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.001064\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.001055\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.001077\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.001058\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.001070\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.001072\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.001067\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.001033\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.001013\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.001078\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.001038\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.001046\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.001088\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.001099\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.001105\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.001060\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.001091\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.001062\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.001061\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.001038\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.001082\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.001096\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.001056\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.001096\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.001074\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.001077\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.001073\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.001097\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.001003\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.001082\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.001019\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.001066\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.001088\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.001108\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.001031\n",
      "====> Epoch: 8 Average loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.001029\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.001047\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.001103\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.001100\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.001089\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.001073\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.001062\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.001039\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.001036\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.001082\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.001104\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.001054\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.001086\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.001049\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.001018\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.001070\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.001081\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.001032\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.001051\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.001064\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.001052\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.001076\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.001077\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.001034\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.001024\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.001096\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.001036\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.001038\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.001109\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.001041\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.001049\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.001074\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.001085\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.001091\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.001045\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.001073\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.001021\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.001070\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.001050\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.001061\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.001071\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.001064\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.001027\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.001043\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.001087\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.001083\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.001094\n",
      "====> Epoch: 9 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.001073\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.001088\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.001060\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.001087\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.001048\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.001016\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.001018\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.001064\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.001089\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.001053\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.001087\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.001071\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.001034\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.001068\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.001072\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.001036\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.001078\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.001061\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.001059\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.001070\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.001069\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.001091\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.001092\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.001087\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.001073\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.001079\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.001039\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.001049\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.001047\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.001066\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.001036\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.001041\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.001060\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.001043\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.001067\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.001064\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.001078\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.001057\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.001035\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.001063\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.001078\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.001021\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.001042\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.001077\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.001066\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.001070\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.001037\n",
      "====> Epoch: 10 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.001052\n",
      "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 0.001023\n",
      "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 0.001063\n",
      "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 0.001072\n",
      "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 0.001056\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.001022\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 0.001073\n",
      "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 0.001079\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.001030\n",
      "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 0.001057\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.001042\n",
      "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 0.001066\n",
      "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 0.001072\n",
      "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 0.001038\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 0.001125\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.001066\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.001098\n",
      "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 0.001016\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 0.001092\n",
      "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 0.001025\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.001043\n",
      "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 0.001060\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 0.001047\n",
      "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 0.001062\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.001051\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.001048\n",
      "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 0.001053\n",
      "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 0.001051\n",
      "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 0.001077\n",
      "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 0.001075\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.001078\n",
      "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 0.001071\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.001089\n",
      "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 0.001065\n",
      "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 0.001051\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.001058\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 0.001090\n",
      "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 0.001052\n",
      "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 0.000970\n",
      "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 0.001054\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.001043\n",
      "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 0.001038\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 0.001071\n",
      "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 0.001020\n",
      "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 0.001062\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.001045\n",
      "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 0.001054\n",
      "====> Epoch: 11 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.001053\n",
      "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 0.001019\n",
      "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 0.001009\n",
      "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 0.001063\n",
      "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 0.001070\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.001066\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 0.001072\n",
      "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 0.001058\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.001073\n",
      "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 0.001064\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.001022\n",
      "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 0.001023\n",
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 0.001036\n",
      "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 0.001082\n",
      "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 0.001077\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.001030\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.001043\n",
      "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 0.001049\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 0.001030\n",
      "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 0.001072\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.001082\n",
      "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 0.001055\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 0.001045\n",
      "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 0.001045\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.001058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.001029\n",
      "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 0.001021\n",
      "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 0.001033\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 0.001039\n",
      "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 0.001081\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.001074\n",
      "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 0.001038\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.001034\n",
      "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 0.001045\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 0.001046\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.001046\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 0.001052\n",
      "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 0.001041\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 0.001074\n",
      "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 0.001069\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.001085\n",
      "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 0.001112\n",
      "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 0.001068\n",
      "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 0.001049\n",
      "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 0.001044\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.001019\n",
      "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 0.001031\n",
      "====> Epoch: 12 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.001099\n",
      "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 0.001079\n",
      "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 0.001072\n",
      "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 0.001042\n",
      "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 0.001043\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.001067\n",
      "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 0.001027\n",
      "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 0.001059\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.001055\n",
      "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 0.001036\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.001086\n",
      "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 0.001060\n",
      "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 0.001039\n",
      "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 0.001054\n",
      "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 0.001012\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.001031\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.001043\n",
      "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 0.001046\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 0.001032\n",
      "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 0.001057\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.001033\n",
      "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 0.001054\n",
      "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 0.001063\n",
      "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 0.001043\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.001042\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.001046\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 0.001026\n",
      "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 0.001032\n",
      "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 0.001026\n",
      "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 0.001069\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.000991\n",
      "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 0.001061\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.001063\n",
      "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 0.001042\n",
      "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 0.001030\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.001054\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 0.001074\n",
      "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 0.001021\n",
      "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 0.001067\n",
      "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 0.001003\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.001034\n",
      "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 0.001060\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 0.001021\n",
      "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 0.001090\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 0.001063\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.001045\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 0.001062\n",
      "====> Epoch: 13 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.001043\n",
      "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.001026\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.001063\n",
      "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.001070\n",
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.001042\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.001023\n",
      "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.001028\n",
      "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.001040\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.001052\n",
      "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.001056\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.001037\n",
      "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.001032\n",
      "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.001075\n",
      "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.001075\n",
      "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.001035\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.001046\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.001038\n",
      "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.001084\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.001060\n",
      "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.001065\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.001027\n",
      "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.001036\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.001030\n",
      "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.001023\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.001046\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.001045\n",
      "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.001025\n",
      "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.001027\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.001033\n",
      "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.001093\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.001035\n",
      "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.001057\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.001070\n",
      "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.001026\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.001052\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.001038\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.001073\n",
      "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.001066\n",
      "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.001057\n",
      "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.001027\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.001057\n",
      "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.001044\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.001066\n",
      "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.001054\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.001057\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.001042\n",
      "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.001013\n",
      "====> Epoch: 14 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.001042\n",
      "Train Epoch: 15 [1280/60000 (2%)]\tLoss: 0.001027\n",
      "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 0.001070\n",
      "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 0.001060\n",
      "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 0.001013\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.001078\n",
      "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 0.001035\n",
      "Train Epoch: 15 [8960/60000 (15%)]\tLoss: 0.001044\n",
      "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.001039\n",
      "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 0.001042\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.001070\n",
      "Train Epoch: 15 [14080/60000 (23%)]\tLoss: 0.001036\n",
      "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 0.001036\n",
      "Train Epoch: 15 [16640/60000 (28%)]\tLoss: 0.001049\n",
      "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 0.001005\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.001045\n",
      "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.001051\n",
      "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 0.001048\n",
      "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 0.001033\n",
      "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 0.001058\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.001041\n",
      "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 0.001042\n",
      "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 0.001026\n",
      "Train Epoch: 15 [29440/60000 (49%)]\tLoss: 0.001073\n",
      "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.001035\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.001064\n",
      "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 0.001044\n",
      "Train Epoch: 15 [34560/60000 (58%)]\tLoss: 0.001060\n",
      "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 0.001100\n",
      "Train Epoch: 15 [37120/60000 (62%)]\tLoss: 0.001054\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.001067\n",
      "Train Epoch: 15 [39680/60000 (66%)]\tLoss: 0.001054\n",
      "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.001050\n",
      "Train Epoch: 15 [42240/60000 (70%)]\tLoss: 0.001027\n",
      "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 0.001042\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.001025\n",
      "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 0.001018\n",
      "Train Epoch: 15 [47360/60000 (79%)]\tLoss: 0.001054\n",
      "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 0.001061\n",
      "Train Epoch: 15 [49920/60000 (83%)]\tLoss: 0.001033\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.001037\n",
      "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 0.001081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 0.001072\n",
      "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 0.001047\n",
      "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 0.001004\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.001012\n",
      "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 0.001021\n",
      "====> Epoch: 15 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "# 64 ensembles de vecteurs ZDIMS-float aléatoires, soit 64 emplacements / MNIST   \n",
    "    sample = Variable(torch.randn(64, ZDIMS))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if CUDA:\n",
    "            sample = sample.cuda()\n",
    "            sample = model.decode(sample).cpu()\n",
    "            \n",
    "            save_image(sample.data.view(64, 1, 28, 28),\n",
    "                   'results/sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(sample.view(64, 1, 28, 28), 'results/sample_continuous.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f379030e828>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the gradient mean value for each FC layer across training\n",
    "#plt.plot(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d execution : 30.8 secondes ---\n"
     ]
    }
   ],
   "source": [
    "# Affichage du temps d execution\n",
    "print(\"Temps d execution : %s secondes ---\" % round((time.time() - start_time),1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
